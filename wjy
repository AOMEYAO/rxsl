# -*- coding:utf-8 -*-
import sys
reload(sys)
sys.setdefaultencoding('utf-8')

import urllib2
from bs4 import BeautifulSoup

import re


sumhref=[]
sumlabel=[]
sumworker=[]
sumtime=[]
#page:(1,1010)

url='http://12345.chengdu.gov.cn/moreMail?page=1'
file=urllib2.urlopen(urllib2.Request(url)).read()
htmlsoup=BeautifulSoup(file,'html.parser',from_encoding='utf-8')
#originstring=htmlsoup.find_all("li")
#print originstring[:-1]

for page in range(1,2):
	url='http://12345.chengdu.gov.cn/moreMail?page='+str(page)
	file=urllib2.urlopen(urllib2.Request(url)).read()

	htmlsoup=BeautifulSoup(file,'html.parser',from_encoding='utf-8')

	#print htmlsoup
	listItem=htmlsoup.find_all("li",class_="f12px")
	#print len(listItem)
	href=['http://12345.chengdu.gov.cn/'+item.find("a")['href'] for item in listItem]

	label=[item.find_all("div",class_='listTit2')[2]['title'] for item in listItem]
	worker=[item.find_all("div",class_='listTit2')[1]['title'] for item in listItem]
	time=[item.find_all("div",class_='listTit8')[2].string for item in listItem]
	sumhref.extend(href)
	sumlabel.extend(label)
	sumworker.extend(worker)
	sumtime.extend(time)
#for href in sumhref:
	#print href
#for label in sumlabel:
	#print label
info=zip(sumhref,sumlabel,sumworker,sumtime)

for i in info:
	print i[0]
	print i[2]
	print i[1]
	print i[3]
	file=urllib2.urlopen(urllib2.Request(i[0])).read()
	htmlsoup=BeautifulSoup(file,'html.parser',from_encoding='utf-8')
	try:
		print htmlsoup.find_all('td',class_="td2 f12pxgrey")[1].string.strip().replace(' ','').replace('\r\n','')

	except Exception:
		print Exception
